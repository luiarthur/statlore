---
layout: page
title: Bayesian Linear Model
math: on
---

# {{ page.title }}

Consider the following model,

$$
\begin{aligned}
    \bm y \mid \bm\beta &\sim \MvNormal(\bm X \bm \beta, \bm\Sigma) \\
    \bm \beta & \sim \MvNormal(\bm m, \bm S)
\end{aligned}
$$

Using section 14 from [BDA3][1], we can write the
above equivalently as:

$$
\begin{aligned}
    \begin{pmatrix}
        \bm \Sigma ^{-1/2} \bm y \\
        \bm m
    \end{pmatrix} \Bigg| \bm \beta &\sim \MvNormal\p{
        \begin{bmatrix}
            \bm\Sigma^{-1/2} \bm X \\
            \bm I
        \end{bmatrix} \bm \beta,
        \begin{bmatrix}
            \bm I & \bm 0 \\
            \bm 0 & \bm S
        \end{bmatrix}
    }.
\end{aligned}
$$

Thus, we obtain the following posterior for $\bm\beta$:

$$
\begin{aligned}
    \bm \beta \mid \bm y &\sim \MvNormal(\bm m^\star, \bm S^\star),
    \text{ where} \\
    \bm S^\star &= \p{\bm X^T \bm\Sigma^{-1} \bm X + \bm S^{-1}}^{-1} \\
    \bm m^\star &= \bm S^\star 
        \p{\bm X^T \bm\Sigma^{-1} \bm y + \bm S^{-1} \bm m} \\
\end{aligned}
$$


[1]: http://www.stat.columbia.edu/~gelman/book/
